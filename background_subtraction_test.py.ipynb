{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:22:05.807559Z",
     "start_time": "2024-09-20T14:22:05.393776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ],
   "id": "3d65d9a912999c68",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-20T14:22:05.813811Z",
     "start_time": "2024-09-20T14:22:05.808755Z"
    }
   },
   "source": [
    "\n",
    "video_folder = \"/home/persie/Videos/mokap/\"\n",
    "session_id = os.listdir(video_folder)\n",
    "video_file = []\n",
    "for folder in session_id:\n",
    "    files = os.listdir(os.path.join(video_folder, folder))\n",
    "    for file in files:\n",
    "        video_file.append(os.path.join(video_folder, folder, file))\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T14:15:51.371190Z",
     "start_time": "2024-09-19T14:15:51.352173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def segment_seeds(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "\n",
    "    # Convert to grayscale\n",
    "    prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create a mask of the same size as the frame\n",
    "    mask = np.zeros_like(prev_gray)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate dense optical flow using Farneback method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        \n",
    "        # Calculate magnitude and angle of 2D vectors\n",
    "        magnitude, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        \n",
    "        # Threshold the magnitude to identify significant movement\n",
    "        movement_mask = (magnitude > 1).astype(np.uint8) * 255\n",
    "        \n",
    "        # Update the cumulative mask\n",
    "        mask = cv2.bitwise_or(mask, movement_mask)\n",
    "        \n",
    "        # Apply morphological operations to clean up the mask\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Find contours in the mask\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Filter contours based on area to ignore small movements\n",
    "        min_area = 100  # Adjust this value based on the size of your seeds\n",
    "        seed_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "\n",
    "        # Draw the seed contours on the original frame\n",
    "        result = frame.copy()\n",
    "        cv2.drawContours(result, seed_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Segmented Seeds', result)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update previous frame\n",
    "        prev_gray = gray\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ],
   "id": "e3a6d97549672f13",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:23:04.218903Z",
     "start_time": "2024-09-20T14:23:04.212465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Initialise Background\n",
    "# To initialise the background, I'm going to take the median value of the video pixels\n",
    "def initialise_background(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "    # Read the first frame, but discard as first frame is blank\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        #return\n",
    "        \n",
    "    # Convert to grayscale\n",
    "    ret, first_frame = cap.read()\n",
    "    frame_array = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sample_rate = 15\n",
    "    fno = 1\n",
    "    while ret:\n",
    "        if fno % sample_rate == 0:\n",
    "            ret, frame = cap.retrieve()\n",
    "            if not ret:\n",
    "                break\n",
    "                    # Convert current frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frame_array = np.dstack((frame_array,gray))\n",
    "            fno += 1\n",
    "        else:\n",
    "            # read next frame\n",
    "            ret = cap.grab()\n",
    "            fno += 1\n",
    "  \n",
    "    print(frame_array.shape)  \n",
    "    median = np.median(frame_array, axis=2).astype(dtype=np.uint8)\n",
    "    mean = np.mean(frame_array, axis=2).astype(dtype=np.uint8)    \n",
    "    sigma = np.std(frame_array, axis=2).astype(dtype=np.uint8)\n",
    "\n",
    "    return mean, sigma, median\n",
    "  "
   ],
   "id": "319c6213e725dea2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:27:43.692233Z",
     "start_time": "2024-09-19T16:27:43.688846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Background Update\n",
    "def segment_seeds5(video_path, bgs, variance):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        fg_mask = bgs.apply(gray, None, 0.0)\n",
    "        #masked_fg = cv2.inRange(gray, variance)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow('FG Mask', fg_mask)\n",
    "        #cv2.imshow('masked fg', )\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "b288a8e029e049e4",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:20:30.058555Z",
     "start_time": "2024-09-19T16:20:30.055419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_bgs(background_image):\n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2(history=5, varThreshold=30, detectShadows=True)\n",
    "        \n",
    "    #blur_background = cv2.blur(background_image, (20, 20))\n",
    "    back_sub.apply(background_image, None, 1)\n",
    "    return back_sub\n",
    "    "
   ],
   "id": "e10f4de7353cb39",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:36:11.599050Z",
     "start_time": "2024-09-20T14:36:11.587510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_bgs2(video_path, median_frame, clearest_frame):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "    # Read the first frame, but discard as first frame is blank\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        #return\n",
    "    n_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)    \n",
    "    sample_rate = 15\n",
    "    \n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=30, detectShadows=True)\n",
    "    back_sub.apply(clearest_frame, None, 1)\n",
    "    #back_sub.apply(median_frame, None, 0.5)\n",
    "    \n",
    "    # # Convert to grayscale\n",
    "    # ret, first_frame = cap.read()    \n",
    "    # \n",
    "    # fno = 1\n",
    "    # while ret:\n",
    "    #     if fno % sample_rate == 0:\n",
    "    #         ret, frame = cap.retrieve()\n",
    "    #         if not ret:\n",
    "    #             break\n",
    "    #                 # Convert current frame to grayscale\n",
    "    #         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #         back_sub.apply(gray, None, (sample_rate/n_frames))\n",
    "    #         fno += 1\n",
    "    #     else:\n",
    "    #         # read next frame\n",
    "    #         ret = cap.grab()\n",
    "    #         fno += 1\n",
    "  \n",
    "    return back_sub\n",
    "    "
   ],
   "id": "bdfe7cd561b6a84c",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:24:04.367694Z",
     "start_time": "2024-09-20T14:23:14.011026Z"
    }
   },
   "cell_type": "code",
   "source": "mean_frame, std_dev_frame, median_frame = initialise_background(video_file[33])\n",
   "id": "14d02e130dfee2ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1440, 496)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:39:52.279370Z",
     "start_time": "2024-09-19T16:39:52.269271Z"
    }
   },
   "cell_type": "code",
   "source": "6938.0/15",
   "id": "291f1282167bfc4f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462.53333333333336"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:36:14.102862Z",
     "start_time": "2024-09-20T14:36:14.044493Z"
    }
   },
   "cell_type": "code",
   "source": "bgs = create_bgs2(video_file[33], median_frame, clear_frame)\n",
   "id": "4ffcb37f88835850",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:26:45.929011Z",
     "start_time": "2024-09-20T14:26:45.806163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(video_file[33])\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 134)\n",
    "ret, clear_frame = cap.read()\n"
   ],
   "id": "d1a5f6988f93473f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:29:05.232798Z",
     "start_time": "2024-09-20T14:29:05.209931Z"
    }
   },
   "cell_type": "code",
   "source": "segment_seeds5(video_file[33], bgs, std_dev_frame)",
   "id": "89d3c05c4b2a029f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segment_seeds5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43msegment_seeds5\u001B[49m(video_file[\u001B[38;5;241m33\u001B[39m], bgs, std_dev_frame)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'segment_seeds5' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:34:04.981179Z",
     "start_time": "2024-09-19T16:32:33.070498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    cv2.imshow('mean', mean_frame)\n",
    "    cv2.imshow('median', median_frame)\n",
    "    cv2.imshow('std_dev', std_dev_frame)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "f28ec75d1dde88e5",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:27:16.414457Z",
     "start_time": "2024-09-20T14:27:16.408801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def outlineseed2(video_path, bgs, mean, var):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        fg_mask = bgs.apply(gray, None, 0.0)\n",
    "        cv2.imshow('fg_mask', fg_mask)\n",
    "        \n",
    "        \n",
    "        # noise removal\n",
    "        sure_fg = cv2.threshold(fg_mask, 254, 255, cv2.THRESH_BINARY)[1]\n",
    "        sure_fg = cv2.erode(sure_fg, kernel, iterations=1)\n",
    "        \n",
    "\n",
    "        sure_bg = cv2.threshold(fg_mask, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "        sure_bg = cv2.erode(sure_bg, kernel, iterations=1)\n",
    "        sure_bg = cv2.dilate(sure_bg, kernel, iterations=1)\n",
    "        \n",
    "\n",
    "        cv2.imshow('sure_fg', sure_fg)\n",
    "        cv2.imshow('sure_bg', sure_bg)\n",
    "        unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "        cv2.imshow('unknown', unknown)\n",
    "        # Marker labelling\n",
    "        ret, markers = cv2.connectedComponents(sure_fg)\n",
    "         \n",
    "        # Add one to all labels so that sure background is not 0, but 1\n",
    "        markers = markers+1\n",
    "        # Now, mark the region of unknown with zero\n",
    "        markers[unknown==255] = 0\n",
    "        markers = cv2.watershed(frame,markers)\n",
    "        frame[markers == -1] = [255,0,0]\n",
    "        \n",
    "        cv2.imshow('frame', frame)\n",
    "        # \n",
    "        # # Calculate dense optical flow using Farneback method\n",
    "        # flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, pyr_scale=0.7, levels=2, winsize=40, iterations=3, poly_n=7, poly_sigma=1.9, flags=0)\n",
    "        # \n",
    "        # # Calculate magnitude and angle of 2D vectors\n",
    "        # magnitude, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        # \n",
    "        # hsv[..., 0] = ang*180/np.pi/2\n",
    "        # hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        # bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        # \n",
    "        # cv2.imshow('frame2', bgr)\n",
    "        # \n",
    "        # # Threshold the magnitude to identify significant movement\n",
    "        # movement_mask = (magnitude > 1).astype(np.uint8) * 255\n",
    "        # \n",
    "        # # Update the cumulative mask\n",
    "        # #mask = cv2.bitwise_or(mask, movement_mask)\n",
    "        # movement = hsv[..., 2]\n",
    "        # # Apply morphological operations to clean up the mask\n",
    "        # kernel = np.ones((5,5), np.uint8)\n",
    "        # movement_close = cv2.morphologyEx(movement, cv2.MORPH_CLOSE, kernel)\n",
    "        # movement_open = cv2.morphologyEx(movement_close, cv2.MORPH_OPEN, kernel)\n",
    "        # \n",
    "        # # Find contours in the mask\n",
    "        # contours, _ = cv2.findContours(movement_open, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # \n",
    "        # # Filter contours based on area to ignore small movements\n",
    "        # min_area = 100  # Adjust this value based on the size of your seeds\n",
    "        # seed_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "        # \n",
    "        # # Draw the seed contours on the original frame\n",
    "        # result = frame.copy()\n",
    "        # cv2.drawContours(result, seed_contours, -1, (0, 255, 0), 2)\n",
    "        # \n",
    "        # #Display the result\n",
    "        # cv2.imshow('Segmented Seeds', result)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update previous frame\n",
    "        prev_gray = gray\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "af3a88a1d86613b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:37:33.115060Z",
     "start_time": "2024-09-20T14:36:18.982868Z"
    }
   },
   "cell_type": "code",
   "source": "outlineseed2(video_file[33], bgs, mean_frame, std_dev_frame)",
   "id": "a44251e9d32f069e",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:19:06.364773Z",
     "start_time": "2024-09-19T16:19:06.361287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_frame(video_path, frame_id):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        # ret, frame = cap.read()\n",
    "        # if not ret:\n",
    "        #     return\n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "9d78eb0e1dddeb05",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:19:43.297549Z",
     "start_time": "2024-09-19T16:19:11.654893Z"
    }
   },
   "cell_type": "code",
   "source": "show_frame(video_file[33], 134)",
   "id": "ca450b40a6357929",
   "outputs": [],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
