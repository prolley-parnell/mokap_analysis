{
 "cells": [
  {
   "cell_type": "code",
   "id": "3d65d9a912999c68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:59:13.326241Z",
     "start_time": "2024-10-22T14:59:13.158662Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-10-22T14:59:14.595980Z",
     "start_time": "2024-10-22T14:59:14.591822Z"
    }
   },
   "source": [
    "\n",
    "video_folder = \"/home/persie/Videos/mokap/\"\n",
    "session_id = os.listdir(video_folder)\n",
    "video_file = []\n",
    "for folder in session_id:\n",
    "    files = os.listdir(os.path.join(video_folder, folder))\n",
    "    for file in files:\n",
    "        video_file.append(os.path.join(video_folder, folder, file))\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "319c6213e725dea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:59:01.242100Z",
     "start_time": "2024-10-22T14:59:01.238305Z"
    }
   },
   "source": [
    "#Initialise Background\n",
    "# To initialise the background, I'm going to take the median value of the video pixels\n",
    "def initialise_background(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "    # Read the first frame, but discard as first frame is blank\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        #return\n",
    "        \n",
    "    # Convert to grayscale\n",
    "    ret, first_frame = cap.read()\n",
    "    frame_array = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sample_rate = 50\n",
    "    fno = 1\n",
    "    while ret:\n",
    "        if fno % sample_rate == 0:\n",
    "            ret, frame = cap.retrieve()\n",
    "            if not ret:\n",
    "                break\n",
    "                    # Convert current frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frame_array = np.dstack((frame_array,gray))\n",
    "            fno += 1\n",
    "        else:\n",
    "            # read next frame\n",
    "            ret = cap.grab()\n",
    "            fno += 1\n",
    "  \n",
    "    print(frame_array.shape)  \n",
    "    median = np.median(frame_array, axis=2).astype(dtype=np.uint8)\n",
    "    # mean = np.mean(frame_array, axis=2).astype(dtype=np.uint8)    \n",
    "    # sigma = np.std(frame_array, axis=2).astype(dtype=np.uint8)\n",
    "\n",
    "    return median\n",
    "  "
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "b288a8e029e049e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:56:55.919214Z",
     "start_time": "2024-10-22T14:56:55.908213Z"
    }
   },
   "source": [
    "#Background Update\n",
    "def segment_seeds(video_path, bgs):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (7, 7), sigmaX=0, sigmaY=0)\n",
    "        cv2.imshow('blurred frame', blur)\n",
    "        fg_mask = bgs.apply(blur, None, 0.0)\n",
    "        #masked_fg = cv2.inRange(gray, variance)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow('FG Mask', fg_mask)\n",
    "        #cv2.imshow('masked fg', )\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "431e94e4375e8918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:56:57.726623Z",
     "start_time": "2024-10-22T14:56:57.721005Z"
    }
   },
   "source": [
    "#Background Update\n",
    "def segment_seeds_2(video_path, bgs_short, bgs_long):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        fg_mask = bgs_short.apply(gray, None, 0.0)\n",
    "        move_mask = bgs_long.apply(gray, None, 0.01)\n",
    "        \n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow('Short Mask', fg_mask)\n",
    "        cv2.imshow('Long Mask', move_mask)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "cbcdf3994b0e086a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:56:59.679040Z",
     "start_time": "2024-10-22T14:56:59.675860Z"
    }
   },
   "source": [
    "def create_bgs_short(clearest_frame):\n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=9, detectShadows=True)\n",
    "    \n",
    "    back_sub.setShadowThreshold(0.49)\n",
    "    \n",
    "    back_sub.apply(clearest_frame, None, 1)\n",
    "  \n",
    "    return back_sub\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "72eec9480b23491a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:09:15.933161Z",
     "start_time": "2024-10-02T15:08:06.529589Z"
    }
   },
   "outputs": [],
   "source": [
    "def change_var_callback(val):\n",
    "    bgs_long.setVarThreshold(val)\n",
    "    \n",
    "def change_hist_callback(val):\n",
    "    bgs_long.setHistory(val)\n",
    "    \n",
    "def change_shadow_callback(val):\n",
    "    new_val = val / 100\n",
    "    bgs_long.setShadowThreshold(new_val)\n",
    "\n",
    "def change_complexity_reduction_callback(val):\n",
    "    new_val = val / 10000\n",
    "    bgs_long.setComplexityReductionThreshold(new_val)\n",
    "\n",
    "def change_bgd_ratio_callback(val):\n",
    "    new_val = val / 100\n",
    "    bgs_long.setBackgroundRatio(new_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "source_window = 'Long Mask'\n",
    "cv2.namedWindow(source_window, cv2.WINDOW_NORMAL)\n",
    "max_var = 250\n",
    "max_hist = 10000\n",
    "max_shadow = 100\n",
    "max_complexity = 100\n",
    "\n",
    "thresh = 10 # initial threshold\n",
    "cv2.createTrackbar('varThreshold:', source_window, thresh, max_var, change_var_callback)\n",
    "cv2.createTrackbar('shadow:', source_window, 6, max_shadow, change_shadow_callback)\n",
    "cv2.createTrackbar('complexityReduction:', source_window, 0, max_complexity, change_complexity_reduction_callback)\n",
    "\n",
    "\n",
    "segment_seeds_2(video_file[33], bgs_short, bgs_long)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ed359c9c6867ab21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:57:04.617875Z",
     "start_time": "2024-10-22T14:57:04.613999Z"
    }
   },
   "source": [
    "  \n",
    "def create_bgs_long(video_path, sample_rate=50):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "    # Read the first frame, but discard as first frame is blank\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2(history=1000, varThreshold=11, detectShadows=True)\n",
    "    back_sub.setShadowThreshold(0.049)\n",
    "    \n",
    "    fno = 1\n",
    "    while ret:\n",
    "        if fno % sample_rate == 0:\n",
    "            ret, frame = cap.retrieve()\n",
    "            if not ret:\n",
    "                break\n",
    "            # Convert current frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            back_sub.apply(gray, None, 0.1)\n",
    "            fno += 1\n",
    "        else:\n",
    "            # read next frame\n",
    "            ret = cap.grab()\n",
    "            fno += 1\n",
    "\n",
    "\n",
    "    return back_sub\n",
    "  "
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "fd952814ddc90665",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:01:42.385014Z",
     "start_time": "2024-10-22T15:01:42.338608Z"
    }
   },
   "source": [
    "cap = cv2.VideoCapture(\"/home/persie/Videos/mokap/240809-1240/240809-1240_cam2_banana_session23.mp4\")\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 10)\n",
    "ret, frame = cap.read()\n",
    "clear_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "e15684f8617c290e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:59:35.237150Z",
     "start_time": "2024-10-22T14:59:25.194427Z"
    }
   },
   "source": "median_frame = initialise_background(\"/home/persie/Videos/mokap/240809-1240/240809-1240_cam2_banana_session23.mp4\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1440, 130)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "d21c5ceced0371f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:00:53.586618Z",
     "start_time": "2024-10-22T15:00:53.565357Z"
    }
   },
   "source": [
    "while True:\n",
    "    cv2.imshow('median', median_frame)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "f523b2dc5e7592d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:04:59.101416Z",
     "start_time": "2024-10-22T15:04:59.073139Z"
    }
   },
   "source": [
    "\n",
    "bgs_short = create_bgs_short(clear_frame)"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "91b1e334b4cb9e3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:05:12.231846Z",
     "start_time": "2024-10-22T15:05:00.877137Z"
    }
   },
   "source": "bgs_long = create_bgs_long(\"/home/persie/Videos/mokap/240809-1240/240809-1240_cam2_banana_session23.mp4\", 15)\n",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "57770686e2e6c50e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:06:29.269532Z",
     "start_time": "2024-10-22T15:05:41.739443Z"
    }
   },
   "source": "segment_seeds_2(\"/home/persie/Videos/mokap/240809-1240/240809-1240_cam2_banana_session23.mp4\", bgs_short, bgs_long)",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "4389ceb2690f6e13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:59:37.460168Z",
     "start_time": "2024-10-22T15:58:11.735388Z"
    }
   },
   "source": [
    "def thresh_callback(val):\n",
    "    global thresh\n",
    "    thresh = val\n",
    "    \n",
    "\n",
    "# Create Window\n",
    "source_window = 'Source'\n",
    "cv2.namedWindow(source_window, cv2.WINDOW_NORMAL)\n",
    "max_thresh = 255\n",
    "\n",
    "thresh = 255 # initial threshold\n",
    "cv2.createTrackbar('Canny thresh:', source_window, thresh, max_thresh, thresh_callback)\n",
    "thresh_callback(thresh)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(video_file[33])\n",
    "# Read the first frame\n",
    "ret, first_frame = cap.read()\n",
    "bgs_short = create_bgs_short(clear_frame)\n",
    "bgs_long = create_bgs_long(video_file[33])\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    fg_mask = bgs_short.apply(gray, None, 0)\n",
    "    move_mask = bgs_long.apply(gray, None, 0.1)\n",
    "\n",
    "    cv2.imshow('Source', gray)\n",
    "    cv2.imshow('FG Mask', fg_mask)\n",
    "    cv2.imshow('Move Mask', move_mask)\n",
    "    blur_fg = cv2.blur(fg_mask, (3,3))\n",
    "    # Detect edges using Canny\n",
    "    canny_output = cv2.Canny(blur_fg, thresh, thresh * 2)\n",
    "    # Find contours\n",
    "    contours,_ = cv2.findContours(canny_output, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_L1)#cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Find the convex hull object for each contour\n",
    "    hull_list = []\n",
    "    for i in range(len(contours)):\n",
    "        hull = cv2.convexHull(contours[i])\n",
    "        hull_list.append(hull)\n",
    "    # Draw contours + hull results\n",
    "    drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(len(contours)):\n",
    "        color = (254 ,254,254)\n",
    "        cv2.drawContours(drawing, contours, i, color)\n",
    "        cv2.drawContours(drawing, hull_list, i, color)\n",
    "    # Show in a window\n",
    "    cv2.imshow('Contours', drawing)\n",
    "    \n",
    "\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "89d3c05c4b2a029f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:01:57.925864Z",
     "start_time": "2024-10-22T15:01:57.907499Z"
    }
   },
   "source": [
    "bgs = create_bgs_short(clear_frame)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "af3a88a1d86613b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:02:48.423952Z",
     "start_time": "2024-10-22T15:02:48.418594Z"
    }
   },
   "source": [
    "def outlineseed(video_path, bgs):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        fg_mask = bgs.apply(gray, None, 0.0)\n",
    "        cv2.imshow('fg_mask', fg_mask)\n",
    "        \n",
    "        \n",
    "        # noise removal\n",
    "        sure_fg = cv2.threshold(fg_mask, 254, 255, cv2.THRESH_BINARY)[1]\n",
    "        sure_fg = cv2.erode(sure_fg, kernel, iterations=1)\n",
    "        \n",
    "\n",
    "        sure_bg = cv2.threshold(fg_mask, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "        sure_bg = cv2.erode(sure_bg, kernel, iterations=1)\n",
    "        sure_bg = cv2.dilate(sure_bg, kernel, iterations=1)\n",
    "        \n",
    "\n",
    "        cv2.imshow('sure_fg', sure_fg)\n",
    "        cv2.imshow('sure_bg', sure_bg)\n",
    "        unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "        cv2.imshow('unknown', unknown)\n",
    "        # Marker labelling\n",
    "        ret, markers = cv2.connectedComponents(sure_fg)\n",
    "         \n",
    "        # Add one to all labels so that sure background is not 0, but 1\n",
    "        markers = markers+1\n",
    "        # Now, mark the region of unknown with zero\n",
    "        markers[unknown==255] = 0\n",
    "        markers = cv2.watershed(frame,markers)\n",
    "        frame[markers == -1] = [255,0,0]\n",
    "        \n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update previous frame\n",
    "        prev_gray = gray\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "9d78eb0e1dddeb05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:02:36.575473Z",
     "start_time": "2024-10-22T15:02:36.571676Z"
    }
   },
   "source": [
    "def show_frame(video_path, frame_id):\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "ca450b40a6357929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:02:40.383183Z",
     "start_time": "2024-10-22T15:02:38.485110Z"
    }
   },
   "source": "show_frame(\"/home/persie/Videos/mokap/240809-1240/240809-1240_cam2_banana_session23.mp4\", 10)",
   "outputs": [],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
