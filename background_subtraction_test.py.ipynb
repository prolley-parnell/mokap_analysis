{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T20:14:23.504095Z",
     "start_time": "2024-09-25T20:14:23.335519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ],
   "id": "3d65d9a912999c68",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-25T20:14:24.653262Z",
     "start_time": "2024-09-25T20:14:24.648041Z"
    }
   },
   "source": [
    "\n",
    "video_folder = \"/home/persie/Videos/mokap/\"\n",
    "session_id = os.listdir(video_folder)\n",
    "video_file = []\n",
    "for folder in session_id:\n",
    "    files = os.listdir(os.path.join(video_folder, folder))\n",
    "    for file in files:\n",
    "        video_file.append(os.path.join(video_folder, folder, file))\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:23:04.218903Z",
     "start_time": "2024-09-20T14:23:04.212465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Initialise Background\n",
    "# To initialise the background, I'm going to take the median value of the video pixels\n",
    "def initialise_background(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "    # Read the first frame, but discard as first frame is blank\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        #return\n",
    "        \n",
    "    # Convert to grayscale\n",
    "    ret, first_frame = cap.read()\n",
    "    frame_array = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sample_rate = 15\n",
    "    fno = 1\n",
    "    while ret:\n",
    "        if fno % sample_rate == 0:\n",
    "            ret, frame = cap.retrieve()\n",
    "            if not ret:\n",
    "                break\n",
    "                    # Convert current frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frame_array = np.dstack((frame_array,gray))\n",
    "            fno += 1\n",
    "        else:\n",
    "            # read next frame\n",
    "            ret = cap.grab()\n",
    "            fno += 1\n",
    "  \n",
    "    print(frame_array.shape)  \n",
    "    median = np.median(frame_array, axis=2).astype(dtype=np.uint8)\n",
    "    mean = np.mean(frame_array, axis=2).astype(dtype=np.uint8)    \n",
    "    sigma = np.std(frame_array, axis=2).astype(dtype=np.uint8)\n",
    "\n",
    "    return mean, sigma, median\n",
    "  "
   ],
   "id": "319c6213e725dea2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T20:26:45.211875Z",
     "start_time": "2024-09-25T20:26:45.207135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Background Update\n",
    "def segment_seeds(video_path, bgs):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (7, 7), sigmaX=0, sigmaY=0)\n",
    "        cv2.imshow('blurred frame', blur)\n",
    "        fg_mask = bgs.apply(blur, None, 0.0)\n",
    "        #masked_fg = cv2.inRange(gray, variance)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow('FG Mask', fg_mask)\n",
    "        #cv2.imshow('masked fg', )\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "b288a8e029e049e4",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T20:18:27.888640Z",
     "start_time": "2024-09-25T20:18:27.885140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_bgs(video_path, clearest_frame):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "    # Read the first frame, but discard as first frame is blank\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=30, detectShadows=True)\n",
    "    \n",
    "    back_sub.apply(clearest_frame, None, 1)\n",
    "  \n",
    "    return back_sub\n",
    "    "
   ],
   "id": "bdfe7cd561b6a84c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T20:24:58.051719Z",
     "start_time": "2024-09-25T20:24:57.909448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(video_file[33])\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 134)\n",
    "ret, clear_frame = cap.read()\n"
   ],
   "id": "d1a5f6988f93473f",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T20:27:51.995943Z",
     "start_time": "2024-09-25T20:26:49.819999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bgs = create_bgs(video_file[33], clear_frame)\n",
    "segment_seeds(video_file[33], bgs)"
   ],
   "id": "89d3c05c4b2a029f",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T20:14:21.027414Z",
     "start_time": "2024-09-25T20:14:21.017072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def outlineseed(video_path, bgs):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        fg_mask = bgs.apply(gray, None, 0.0)\n",
    "        cv2.imshow('fg_mask', fg_mask)\n",
    "        \n",
    "        \n",
    "        # noise removal\n",
    "        sure_fg = cv2.threshold(fg_mask, 254, 255, cv2.THRESH_BINARY)[1]\n",
    "        sure_fg = cv2.erode(sure_fg, kernel, iterations=1)\n",
    "        \n",
    "\n",
    "        sure_bg = cv2.threshold(fg_mask, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "        sure_bg = cv2.erode(sure_bg, kernel, iterations=1)\n",
    "        sure_bg = cv2.dilate(sure_bg, kernel, iterations=1)\n",
    "        \n",
    "\n",
    "        cv2.imshow('sure_fg', sure_fg)\n",
    "        cv2.imshow('sure_bg', sure_bg)\n",
    "        unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "        cv2.imshow('unknown', unknown)\n",
    "        # Marker labelling\n",
    "        ret, markers = cv2.connectedComponents(sure_fg)\n",
    "         \n",
    "        # Add one to all labels so that sure background is not 0, but 1\n",
    "        markers = markers+1\n",
    "        # Now, mark the region of unknown with zero\n",
    "        markers[unknown==255] = 0\n",
    "        markers = cv2.watershed(frame,markers)\n",
    "        frame[markers == -1] = [255,0,0]\n",
    "        \n",
    "        cv2.imshow('frame', frame)\n",
    "        # \n",
    "        # # Calculate dense optical flow using Farneback method\n",
    "        # flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, pyr_scale=0.7, levels=2, winsize=40, iterations=3, poly_n=7, poly_sigma=1.9, flags=0)\n",
    "        # \n",
    "        # # Calculate magnitude and angle of 2D vectors\n",
    "        # magnitude, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        # \n",
    "        # hsv[..., 0] = ang*180/np.pi/2\n",
    "        # hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        # bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        # \n",
    "        # cv2.imshow('frame2', bgr)\n",
    "        # \n",
    "        # # Threshold the magnitude to identify significant movement\n",
    "        # movement_mask = (magnitude > 1).astype(np.uint8) * 255\n",
    "        # \n",
    "        # # Update the cumulative mask\n",
    "        # #mask = cv2.bitwise_or(mask, movement_mask)\n",
    "        # movement = hsv[..., 2]\n",
    "        # # Apply morphological operations to clean up the mask\n",
    "        # kernel = np.ones((5,5), np.uint8)\n",
    "        # movement_close = cv2.morphologyEx(movement, cv2.MORPH_CLOSE, kernel)\n",
    "        # movement_open = cv2.morphologyEx(movement_close, cv2.MORPH_OPEN, kernel)\n",
    "        # \n",
    "        # # Find contours in the mask\n",
    "        # contours, _ = cv2.findContours(movement_open, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # \n",
    "        # # Filter contours based on area to ignore small movements\n",
    "        # min_area = 100  # Adjust this value based on the size of your seeds\n",
    "        # seed_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "        # \n",
    "        # # Draw the seed contours on the original frame\n",
    "        # result = frame.copy()\n",
    "        # cv2.drawContours(result, seed_contours, -1, (0, 255, 0), 2)\n",
    "        # \n",
    "        # #Display the result\n",
    "        # cv2.imshow('Segmented Seeds', result)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update previous frame\n",
    "        prev_gray = gray\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "af3a88a1d86613b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T14:37:33.115060Z",
     "start_time": "2024-09-20T14:36:18.982868Z"
    }
   },
   "cell_type": "code",
   "source": "outlineseed(video_file[33], bgs, mean_frame, std_dev_frame)",
   "id": "a44251e9d32f069e",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:19:06.364773Z",
     "start_time": "2024-09-19T16:19:06.361287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_frame(video_path, frame_id):\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "9d78eb0e1dddeb05",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:19:43.297549Z",
     "start_time": "2024-09-19T16:19:11.654893Z"
    }
   },
   "cell_type": "code",
   "source": "show_frame(video_file[33], 134)",
   "id": "ca450b40a6357929",
   "outputs": [],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
