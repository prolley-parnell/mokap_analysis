{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:10:52.231208Z",
     "start_time": "2024-10-02T12:10:52.224858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ],
   "id": "3d65d9a912999c68",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-02T12:11:10.320415Z",
     "start_time": "2024-10-02T12:11:10.312984Z"
    }
   },
   "source": [
    "\n",
    "video_folder = \"/home/persie/Videos/mokap/\"\n",
    "session_id = os.listdir(video_folder)\n",
    "video_file = []\n",
    "for folder in session_id:\n",
    "    files = os.listdir(os.path.join(video_folder, folder))\n",
    "    for file in files:\n",
    "        video_file.append(os.path.join(video_folder, folder, file))\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:14:24.360666Z",
     "start_time": "2024-10-02T12:14:24.344317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Initialise Background\n",
    "# To initialise the background, I'm going to take the median value of the video pixels\n",
    "def initialise_background(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "    # Read the first frame, but discard as first frame is blank\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        #return\n",
    "        \n",
    "    # Convert to grayscale\n",
    "    ret, first_frame = cap.read()\n",
    "    frame_array = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sample_rate = 50\n",
    "    fno = 1\n",
    "    while ret:\n",
    "        if fno % sample_rate == 0:\n",
    "            ret, frame = cap.retrieve()\n",
    "            if not ret:\n",
    "                break\n",
    "                    # Convert current frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frame_array = np.dstack((frame_array,gray))\n",
    "            fno += 1\n",
    "        else:\n",
    "            # read next frame\n",
    "            ret = cap.grab()\n",
    "            fno += 1\n",
    "  \n",
    "    print(frame_array.shape)  \n",
    "    median = np.median(frame_array, axis=2).astype(dtype=np.uint8)\n",
    "    # mean = np.mean(frame_array, axis=2).astype(dtype=np.uint8)    \n",
    "    # sigma = np.std(frame_array, axis=2).astype(dtype=np.uint8)\n",
    "\n",
    "    return median\n",
    "  "
   ],
   "id": "319c6213e725dea2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:11:14.076849Z",
     "start_time": "2024-10-02T12:11:14.072827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Background Update\n",
    "def segment_seeds(video_path, bgs):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (7, 7), sigmaX=0, sigmaY=0)\n",
    "        cv2.imshow('blurred frame', blur)\n",
    "        fg_mask = bgs.apply(blur, None, 0.0)\n",
    "        #masked_fg = cv2.inRange(gray, variance)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow('FG Mask', fg_mask)\n",
    "        #cv2.imshow('masked fg', )\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "b288a8e029e049e4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:08:03.747663Z",
     "start_time": "2024-10-02T15:08:03.741806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Background Update\n",
    "def segment_seeds_2(video_path, bgs_short, bgs_long):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        fg_mask = bgs_short.apply(gray, None, 0.0)\n",
    "        move_mask = bgs_long.apply(gray, None, 0.01)\n",
    "        \n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow('Short Mask', fg_mask)\n",
    "        cv2.imshow('Long Mask', move_mask)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "431e94e4375e8918",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T14:53:38.439991Z",
     "start_time": "2024-10-02T14:53:38.432048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_bgs_short(clearest_frame):\n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=9, detectShadows=True)\n",
    "    \n",
    "    back_sub.setShadowThreshold(0.49)\n",
    "    \n",
    "    back_sub.apply(clearest_frame, None, 1)\n",
    "  \n",
    "    return back_sub\n",
    "    "
   ],
   "id": "cbcdf3994b0e086a",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:09:15.933161Z",
     "start_time": "2024-10-02T15:08:06.529589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def change_var_callback(val):\n",
    "    bgs_long.setVarThreshold(val)\n",
    "    \n",
    "def change_hist_callback(val):\n",
    "    bgs_long.setHistory(val)\n",
    "    \n",
    "def change_shadow_callback(val):\n",
    "    new_val = val / 100\n",
    "    bgs_long.setShadowThreshold(new_val)\n",
    "\n",
    "def change_complexity_reduction_callback(val):\n",
    "    new_val = val / 10000\n",
    "    bgs_long.setComplexityReductionThreshold(new_val)\n",
    "\n",
    "def change_bgd_ratio_callback(val):\n",
    "    new_val = val / 100\n",
    "    bgs_long.setBackgroundRatio(new_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "source_window = 'Long Mask'\n",
    "cv2.namedWindow(source_window, cv2.WINDOW_NORMAL)\n",
    "max_var = 250\n",
    "max_hist = 10000\n",
    "max_shadow = 100\n",
    "max_complexity = 100\n",
    "\n",
    "thresh = 10 # initial threshold\n",
    "cv2.createTrackbar('varThreshold:', source_window, thresh, max_var, change_var_callback)\n",
    "cv2.createTrackbar('shadow:', source_window, 6, max_shadow, change_shadow_callback)\n",
    "cv2.createTrackbar('complexityReduction:', source_window, 0, max_complexity, change_complexity_reduction_callback)\n",
    "\n",
    "\n",
    "segment_seeds_2(video_file[33], bgs_short, bgs_long)"
   ],
   "id": "72eec9480b23491a",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:06:19.701776Z",
     "start_time": "2024-10-02T15:06:19.694571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "  \n",
    "def create_bgs_long(video_path, sample_rate=50):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "    # Read the first frame, but discard as first frame is blank\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2(history=1000, varThreshold=11, detectShadows=True)\n",
    "    back_sub.setShadowThreshold(0.049)\n",
    "    \n",
    "    fno = 1\n",
    "    while ret:\n",
    "        if fno % sample_rate == 0:\n",
    "            ret, frame = cap.retrieve()\n",
    "            if not ret:\n",
    "                break\n",
    "            # Convert current frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            back_sub.apply(gray, None, 0.1)\n",
    "            fno += 1\n",
    "        else:\n",
    "            # read next frame\n",
    "            ret = cap.grab()\n",
    "            fno += 1\n",
    "\n",
    "\n",
    "    return back_sub\n",
    "  "
   ],
   "id": "ed359c9c6867ab21",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T14:17:36.464817Z",
     "start_time": "2024-10-02T14:17:36.360968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(video_file[33])\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 134)\n",
    "ret, frame = cap.read()\n",
    "clear_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n"
   ],
   "id": "fd952814ddc90665",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:31:58.144431Z",
     "start_time": "2024-10-02T12:31:47.601391Z"
    }
   },
   "cell_type": "code",
   "source": "median_frame = initialise_background(video_file[33])",
   "id": "e15684f8617c290e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1440, 142)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:33:47.651122Z",
     "start_time": "2024-10-02T12:32:18.493361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    cv2.imshow('median', median_frame)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "d21c5ceced0371f9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T14:27:54.244319Z",
     "start_time": "2024-10-02T14:27:54.222939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "bgs_short = create_bgs_short(clear_frame)\n"
   ],
   "id": "f523b2dc5e7592d8",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:06:34.662281Z",
     "start_time": "2024-10-02T15:06:25.139506Z"
    }
   },
   "cell_type": "code",
   "source": "bgs_long = create_bgs_long(video_file[33], 15)\n",
   "id": "91b1e334b4cb9e3f",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:03:52.350812Z",
     "start_time": "2024-10-02T15:03:52.347772Z"
    }
   },
   "cell_type": "code",
   "source": "bgs_long.getVarMin()",
   "id": "9a94afd9971385a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:04:02.840686Z",
     "start_time": "2024-10-02T15:04:02.831429Z"
    }
   },
   "cell_type": "code",
   "source": "bgs_long.getVarMax()",
   "id": "6dda00202c581825",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T14:24:40.150234Z",
     "start_time": "2024-10-02T14:24:40.145425Z"
    }
   },
   "cell_type": "code",
   "source": "bgs_short.setShadowThreshold(0.75)",
   "id": "690186e5cc6c3818",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T14:38:35.756670Z",
     "start_time": "2024-10-02T14:38:35.753813Z"
    }
   },
   "cell_type": "code",
   "source": "bgs_short.getComplexityReductionThreshold()",
   "id": "518cd538a842c696",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05000000074505806"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T14:28:30.736504Z",
     "start_time": "2024-10-02T14:27:56.617966Z"
    }
   },
   "cell_type": "code",
   "source": "segment_seeds_2(video_file[33], bgs_short, bgs_long)",
   "id": "57770686e2e6c50e",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T14:03:02.367674Z",
     "start_time": "2024-10-02T14:02:27.121160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def thresh_callback(val):\n",
    "    global thresh\n",
    "    thresh = val\n",
    "    \n",
    "\n",
    "# Create Window\n",
    "source_window = 'Source'\n",
    "cv2.namedWindow(source_window, cv2.WINDOW_NORMAL)\n",
    "max_thresh = 255\n",
    "\n",
    "thresh = 255 # initial threshold\n",
    "cv2.createTrackbar('Canny thresh:', source_window, thresh, max_thresh, thresh_callback)\n",
    "thresh_callback(thresh)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(video_file[33])\n",
    "# Read the first frame\n",
    "ret, first_frame = cap.read()\n",
    "bgs_short = create_bgs_short(clear_frame)\n",
    "bgs_long = create_bgs_long(video_file[33])\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    fg_mask = bgs_short.apply(gray, None, 0)\n",
    "    move_mask = bgs_long.apply(gray, None, 0.1)\n",
    "\n",
    "    cv2.imshow('Source', gray)\n",
    "    cv2.imshow('FG Mask', fg_mask)\n",
    "    cv2.imshow('Move Mask', move_mask)\n",
    "    blur_fg = cv2.blur(fg_mask, (3,3))\n",
    "    # Detect edges using Canny\n",
    "    canny_output = cv2.Canny(blur_fg, thresh, thresh * 2)\n",
    "    # Find contours\n",
    "    contours,_ = cv2.findContours(canny_output, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_L1)#cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Find the convex hull object for each contour\n",
    "    hull_list = []\n",
    "    for i in range(len(contours)):\n",
    "        hull = cv2.convexHull(contours[i])\n",
    "        hull_list.append(hull)\n",
    "    # Draw contours + hull results\n",
    "    drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(len(contours)):\n",
    "        color = (254 ,254,254)\n",
    "        cv2.drawContours(drawing, contours, i, color)\n",
    "        cv2.drawContours(drawing, hull_list, i, color)\n",
    "    # Show in a window\n",
    "    cv2.imshow('Contours', drawing)\n",
    "    \n",
    "\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "4389ceb2690f6e13",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bgs = create_bgs_short(clear_frame)",
   "id": "89d3c05c4b2a029f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def outlineseed(video_path, bgs):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Read the first frame\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert current frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        fg_mask = bgs.apply(gray, None, 0.0)\n",
    "        cv2.imshow('fg_mask', fg_mask)\n",
    "        \n",
    "        \n",
    "        # noise removal\n",
    "        sure_fg = cv2.threshold(fg_mask, 254, 255, cv2.THRESH_BINARY)[1]\n",
    "        sure_fg = cv2.erode(sure_fg, kernel, iterations=1)\n",
    "        \n",
    "\n",
    "        sure_bg = cv2.threshold(fg_mask, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "        sure_bg = cv2.erode(sure_bg, kernel, iterations=1)\n",
    "        sure_bg = cv2.dilate(sure_bg, kernel, iterations=1)\n",
    "        \n",
    "\n",
    "        cv2.imshow('sure_fg', sure_fg)\n",
    "        cv2.imshow('sure_bg', sure_bg)\n",
    "        unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "        cv2.imshow('unknown', unknown)\n",
    "        # Marker labelling\n",
    "        ret, markers = cv2.connectedComponents(sure_fg)\n",
    "         \n",
    "        # Add one to all labels so that sure background is not 0, but 1\n",
    "        markers = markers+1\n",
    "        # Now, mark the region of unknown with zero\n",
    "        markers[unknown==255] = 0\n",
    "        markers = cv2.watershed(frame,markers)\n",
    "        frame[markers == -1] = [255,0,0]\n",
    "        \n",
    "        cv2.imshow('frame', frame)\n",
    "\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Update previous frame\n",
    "        prev_gray = gray\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "af3a88a1d86613b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_frame(video_path, frame_id):\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "9d78eb0e1dddeb05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "show_frame(video_file[33], 134)",
   "id": "ca450b40a6357929",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
