{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T13:58:17.218964Z",
     "start_time": "2024-09-24T13:58:17.216988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ],
   "id": "a0f5cff431e6314b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T13:58:18.783184Z",
     "start_time": "2024-09-24T13:58:18.775895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "video_folder = \"/home/persie/Videos/mokap/\"\n",
    "session_id = os.listdir(video_folder)\n",
    "video_file = []\n",
    "for folder in session_id:\n",
    "    files = os.listdir(os.path.join(video_folder, folder))\n",
    "    for file in files:\n",
    "        video_file.append(os.path.join(video_folder, folder, file))\n"
   ],
   "id": "8c120fa4d3d7216b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T13:58:20.612223Z",
     "start_time": "2024-09-24T13:58:20.492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(video_file[33])\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 134)\n",
    "ret, frame = cap.read()\n",
    "clear_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ],
   "id": "11529d8e8bee661f",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T14:13:03.097109Z",
     "start_time": "2024-09-24T14:13:03.090696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def draw_circle(event,x,y,flags,param):\n",
    "    #Because of the use of global variables, they must be defined before using them, outside of any functions\n",
    "    global radius, text_image, mask  \n",
    "    if flags == cv2.EVENT_FLAG_SHIFTKEY:\n",
    "            cv2.circle(mask,(x,y),radius,(0,0,0),-1)    \n",
    "    if flags == cv2.EVENT_FLAG_LBUTTON:\n",
    "        cv2.circle(mask,(x,y),radius,(255,255,255),-1)      \n",
    "        \n",
    "    text_image = cv2.rectangle(text_image, (0, 70), (35, 40), (255, 255, 255), -1)    \n",
    "    text_image = cv2.putText(text_image, str(radius), (0, 65), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.8, color=(0, 0, 255), thickness=2)         \n",
    "        "
   ],
   "id": "112b80ce98aabe7b",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-20T15:17:18.168483Z",
     "start_time": "2024-09-20T15:17:18.159515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "np.where(mask == 1)\n"
   ],
   "id": "b178be1d4dc11302",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 525,  646,  704,  707,  707,  715,  725,  727,  729,  742,  745,\n",
       "         764,  793,  793,  799,  803,  813,  814,  815,  819,  828,  836,\n",
       "         838,  840,  846,  847,  851,  863,  868,  870,  877,  881,  886,\n",
       "         887,  888,  892,  897,  903,  911,  914,  920,  924,  940,  952,\n",
       "         956,  966,  969,  976,  986, 1008, 1026, 1047, 1056]),\n",
       " array([430, 461, 474, 408, 467, 471, 437, 437, 430, 416, 413, 366, 521,\n",
       "        522, 514, 531, 452, 535, 529, 484, 530, 395, 539, 505, 544, 545,\n",
       "        548, 556, 554, 551, 521, 524, 551, 529, 515, 547, 517, 520, 534,\n",
       "        551, 551, 461, 531, 551, 548, 509, 546, 362, 541, 539, 536, 533,\n",
       "        531]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    " \n",
    " #Select the image pixels and the mask\n",
    "img_object = cv.imread(cv.samples.findFile(args.input1), cv.IMREAD_GRAYSCALE)\n",
    "img_scene = cv.imread(cv.samples.findFile(args.input2), cv.IMREAD_GRAYSCALE)\n",
    "if img_object is None or img_scene is None:\n",
    "    print('Could not open or find the images!')\n",
    "    exit(0)\n",
    " \n",
    "#-- Step 1: Detect the keypoints using SURF Detector, compute the descriptors\n",
    "minHessian = 400\n",
    "detector = cv.xfeatures2d_SURF.create(hessianThreshold=minHessian)\n",
    "keypoints_obj, descriptors_obj = detector.detectAndCompute(img_object, None)\n",
    "keypoints_scene, descriptors_scene = detector.detectAndCompute(img_scene, None)\n",
    " \n",
    "#-- Step 2: Matching descriptor vectors with a FLANN based matcher\n",
    "# Since SURF is a floating-point descriptor NORM_L2 is used\n",
    "matcher = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)\n",
    "knn_matches = matcher.knnMatch(descriptors_obj, descriptors_scene, 2)\n",
    " \n",
    "#-- Filter matches using the Lowe's ratio test\n",
    "ratio_thresh = 0.75\n",
    "good_matches = []\n",
    "for m,n in knn_matches:\n",
    "    if m.distance < ratio_thresh * n.distance:\n",
    "        good_matches.append(m)\n",
    " \n",
    "#-- Draw matches\n",
    "img_matches = np.empty((max(img_object.shape[0], img_scene.shape[0]), img_object.shape[1]+img_scene.shape[1], 3), dtype=np.uint8)\n",
    "cv.drawMatches(img_object, keypoints_obj, img_scene, keypoints_scene, good_matches, img_matches, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    " \n",
    "#-- Localize the object\n",
    "obj = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "scene = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "for i in range(len(good_matches)):\n",
    "    #-- Get the keypoints from the good matches\n",
    "    obj[i,0] = keypoints_obj[good_matches[i].queryIdx].pt[0]\n",
    "    obj[i,1] = keypoints_obj[good_matches[i].queryIdx].pt[1]\n",
    "    scene[i,0] = keypoints_scene[good_matches[i].trainIdx].pt[0]\n",
    "    scene[i,1] = keypoints_scene[good_matches[i].trainIdx].pt[1]\n",
    " \n",
    "H, _ =  cv.findHomography(obj, scene, cv.RANSAC)\n",
    " \n",
    "#-- Get the corners from the image_1 ( the object to be \"detected\" )\n",
    "obj_corners = np.empty((4,1,2), dtype=np.float32)\n",
    "obj_corners[0,0,0] = 0\n",
    "obj_corners[0,0,1] = 0\n",
    "obj_corners[1,0,0] = img_object.shape[1]\n",
    "obj_corners[1,0,1] = 0\n",
    "obj_corners[2,0,0] = img_object.shape[1]\n",
    "obj_corners[2,0,1] = img_object.shape[0]\n",
    "obj_corners[3,0,0] = 0\n",
    "obj_corners[3,0,1] = img_object.shape[0]\n",
    " \n",
    "scene_corners = cv.perspectiveTransform(obj_corners, H)\n",
    " \n",
    "#-- Draw lines between the corners (the mapped object in the scene - image_2 )\n",
    "cv.line(img_matches, (int(scene_corners[0,0,0] + img_object.shape[1]), int(scene_corners[0,0,1])),\\\n",
    "    (int(scene_corners[1,0,0] + img_object.shape[1]), int(scene_corners[1,0,1])), (0,255,0), 4)\n",
    "cv.line(img_matches, (int(scene_corners[1,0,0] + img_object.shape[1]), int(scene_corners[1,0,1])),\\\n",
    "    (int(scene_corners[2,0,0] + img_object.shape[1]), int(scene_corners[2,0,1])), (0,255,0), 4)\n",
    "cv.line(img_matches, (int(scene_corners[2,0,0] + img_object.shape[1]), int(scene_corners[2,0,1])),\\\n",
    "    (int(scene_corners[3,0,0] + img_object.shape[1]), int(scene_corners[3,0,1])), (0,255,0), 4)\n",
    "cv.line(img_matches, (int(scene_corners[3,0,0] + img_object.shape[1]), int(scene_corners[3,0,1])),\\\n",
    "    (int(scene_corners[0,0,0] + img_object.shape[1]), int(scene_corners[0,0,1])), (0,255,0), 4)\n",
    " \n",
    "#-- Show detected matches\n",
    "cv.imshow('Good Matches & Object detection', img_matches)\n",
    " \n",
    "cv.waitKey()"
   ],
   "id": "affb4b1af28bffef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T14:18:26.601977Z",
     "start_time": "2024-09-24T14:18:25.504989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Select frame with object in\n",
    "cap = cv2.VideoCapture(video_file[33])\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 1507)\n",
    "ret, frame = cap.read()\n",
    "object_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ],
   "id": "4b16f5f6ee7631af",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T14:44:42.880026Z",
     "start_time": "2024-09-24T14:44:36.261123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run the mask creation code\n",
    "text_image = object_frame\n",
    "mask = np.zeros_like(object_frame, np.uint8)\n",
    "# Set the initial circle radius\n",
    "radius = 50\n",
    "line_1 = \"Click with the left mouse button to add, double click to remove\"\n",
    "line_2 = \"Up = radius + 5,\"\n",
    "line_3 = \"Down = radius - 5\"\n",
    "text_image = cv2.putText(text_image, line_1, (10, 10), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=2)  \n",
    "text_image = cv2.putText(text_image, line_2, (10, 22), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=2)  \n",
    "text_image = cv2.putText(text_image, line_3, (10, 34), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=2)  \n",
    "combined_image = cv2.bitwise_or(text_image, mask)\n",
    "cv2.namedWindow('Mask On Frame')\n",
    "cv2.imshow('Mask On Frame', combined_image)\n",
    "cv2.setMouseCallback('Mask On Frame',draw_circle)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    combined_image = cv2.bitwise_or(text_image, mask)\n",
    "    cv2.imshow('Mask On Frame',combined_image)\n",
    "    cv2.imshow('Mask',mask)\n",
    "    k = cv2.waitKey(20) & 0xFF\n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "    if k == 82:\n",
    "        #upkey\n",
    "        radius = radius + 5\n",
    "    if k == 84:\n",
    "        #downkey\n",
    "        radius = radius - 5\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "b412ae6b7f7bfc92",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T14:44:44.991335Z",
     "start_time": "2024-09-24T14:44:44.986030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#save the mask separately\n",
    "object_mask = mask"
   ],
   "id": "99ff058915affeb2",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T14:46:37.867859Z",
     "start_time": "2024-09-24T14:46:35.833634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get another test frame\n",
    "cap = cv2.VideoCapture(video_file[33])\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 2934)\n",
    "ret, frame = cap.read()\n",
    "img_scene = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ],
   "id": "c855809302678d4a",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T14:46:40.127102Z",
     "start_time": "2024-09-24T14:46:38.564602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Select the image pixels and the mask and just check that it is alright\n",
    "img_object = cv2.bitwise_and(object_frame, object_mask)\n",
    "\n",
    "if img_object is None or img_scene is None:\n",
    "    print('Could not open or find the images!')\n",
    "    exit(0)\n",
    "\n",
    "cv2.imshow(\"Masked Image\", img_object)\n",
    "cv2.imshow(\"Comparison Scene\", img_scene)\n",
    "while 1:\n",
    "    if cv2.waitKey(20) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ],
   "id": "5be1bb931d49e273",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T14:47:46.874911Z",
     "start_time": "2024-09-24T14:47:46.847824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#-- Step 1: Detect the keypoints using SIFT Detector, compute the descriptors\n",
    "detector = cv2.SIFT_create()\n",
    "keypoints_obj, descriptors_obj = detector.detectAndCompute(img_object, None)\n",
    "keypoints_scene, descriptors_scene = detector.detectAndCompute(img_scene, None)\n",
    " "
   ],
   "id": "33ff035f5aad5f9b",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T14:47:49.822074Z",
     "start_time": "2024-09-24T14:47:49.806768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#-- Step 2: Matching descriptor vectors with a FLANN based matcher\n",
    "# Since SURF is a floating-point descriptor NORM_L2 is used\n",
    "matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "knn_matches = matcher.knnMatch(descriptors_obj, descriptors_scene, 2)\n",
    "\n",
    "\n",
    "#-- Filter matches using the Lowe's ratio test\n",
    "ratio_thresh = 0.75\n",
    "good_matches = []\n",
    "for m,n in knn_matches:\n",
    "    if m.distance < ratio_thresh * n.distance:\n",
    "        good_matches.append(m)\n",
    " \n",
    "#-- Draw matches\n",
    "img_matches = np.empty((max(img_object.shape[0], img_scene.shape[0]), img_object.shape[1]+img_scene.shape[1], 3), dtype=np.uint8)\n",
    "cv2.drawMatches(img_object, keypoints_obj, img_scene, keypoints_scene, good_matches, img_matches, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n"
   ],
   "id": "93b592824ef23614",
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /home/conda/feedstock_root/build_artifacts/libopencv_1723431247556/work/modules/flann/src/miniflann.cpp:336: error: (-210:Unsupported format or combination of formats) in function 'buildIndex_'\n> type=0\n> ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[134], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#-- Step 2: Matching descriptor vectors with a FLANN based matcher\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Since SURF is a floating-point descriptor NORM_L2 is used\u001B[39;00m\n\u001B[1;32m      3\u001B[0m matcher \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mDescriptorMatcher_create(cv2\u001B[38;5;241m.\u001B[39mDescriptorMatcher_FLANNBASED)\n\u001B[0;32m----> 4\u001B[0m knn_matches \u001B[38;5;241m=\u001B[39m \u001B[43mmatcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mknnMatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdescriptors_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdescriptors_scene\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#-- Filter matches using the Lowe's ratio test\u001B[39;00m\n\u001B[1;32m      8\u001B[0m ratio_thresh \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.75\u001B[39m\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.10.0) /home/conda/feedstock_root/build_artifacts/libopencv_1723431247556/work/modules/flann/src/miniflann.cpp:336: error: (-210:Unsupported format or combination of formats) in function 'buildIndex_'\n> type=0\n> "
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T14:47:03.391834Z",
     "start_time": "2024-09-24T14:46:46.590279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#-- Localize the object\n",
    "obj = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "scene = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "for i in range(len(good_matches)):\n",
    "    #-- Get the keypoints from the good matches\n",
    "    obj[i,0] = keypoints_obj[good_matches[i].queryIdx].pt[0]\n",
    "    obj[i,1] = keypoints_obj[good_matches[i].queryIdx].pt[1]\n",
    "    scene[i,0] = keypoints_scene[good_matches[i].trainIdx].pt[0]\n",
    "    scene[i,1] = keypoints_scene[good_matches[i].trainIdx].pt[1]\n",
    " \n",
    "H, _ =  cv2.findHomography(obj, scene, cv2.RANSAC)\n",
    " \n",
    "#-- Get the corners from the image_1 ( the object to be \"detected\" )\n",
    "obj_corners = np.empty((4,1,2), dtype=np.float32)\n",
    "obj_corners[0,0,0] = 0\n",
    "obj_corners[0,0,1] = 0\n",
    "obj_corners[1,0,0] = img_object.shape[1]\n",
    "obj_corners[1,0,1] = 0\n",
    "obj_corners[2,0,0] = img_object.shape[1]\n",
    "obj_corners[2,0,1] = img_object.shape[0]\n",
    "obj_corners[3,0,0] = 0\n",
    "obj_corners[3,0,1] = img_object.shape[0]\n",
    " \n",
    "scene_corners = cv2.perspectiveTransform(obj_corners, H)\n",
    " \n",
    "#-- Draw lines between the corners (the mapped object in the scene - image_2 )\n",
    "cv2.line(img_matches, (int(scene_corners[0,0,0] + img_object.shape[1]), int(scene_corners[0,0,1])),\\\n",
    "    (int(scene_corners[1,0,0] + img_object.shape[1]), int(scene_corners[1,0,1])), (0,255,0), 4)\n",
    "cv2.line(img_matches, (int(scene_corners[1,0,0] + img_object.shape[1]), int(scene_corners[1,0,1])),\\\n",
    "    (int(scene_corners[2,0,0] + img_object.shape[1]), int(scene_corners[2,0,1])), (0,255,0), 4)\n",
    "cv2.line(img_matches, (int(scene_corners[2,0,0] + img_object.shape[1]), int(scene_corners[2,0,1])),\\\n",
    "    (int(scene_corners[3,0,0] + img_object.shape[1]), int(scene_corners[3,0,1])), (0,255,0), 4)\n",
    "cv2.line(img_matches, (int(scene_corners[3,0,0] + img_object.shape[1]), int(scene_corners[3,0,1])),\\\n",
    "    (int(scene_corners[0,0,0] + img_object.shape[1]), int(scene_corners[0,0,1])), (0,255,0), 4)\n",
    " \n",
    "#-- Show detected matches\n",
    "cv2.imshow('Good Matches & Object detection', img_matches)\n",
    "cv2.waitKey()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "64b2b6fe93b12973",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 114,
   "source": [
    "cv2.imshow('Good Matches & Object detection', img_matches)\n",
    "cv2.waitKey()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "d75ac9cfbd4f9428"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
