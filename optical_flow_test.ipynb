{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:32:16.521537Z",
     "start_time": "2024-10-22T14:32:16.308249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ],
   "id": "77a3811bf950cf4b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:32:17.302013Z",
     "start_time": "2024-10-22T14:32:17.298010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "video_folder = \"/home/persie/Videos/mokap/\"\n",
    "session_id = os.listdir(video_folder)\n",
    "video_file = []\n",
    "for folder in session_id:\n",
    "    files = os.listdir(os.path.join(video_folder, folder))\n",
    "    for file in files:\n",
    "        video_file.append(os.path.join(video_folder, folder, file))\n"
   ],
   "id": "2fa20492f9bae5fb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:47:51.222726Z",
     "start_time": "2024-10-22T14:47:51.220908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vid_name = \"/home/persie/Videos/mokap/240809-1240/240809-1240_cam2_banana_session23.mp4\"\n",
    "#Was 33 but then the file ordering changed"
   ],
   "id": "25fe94b0aca0a291",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:47:53.226841Z",
     "start_time": "2024-10-22T14:47:53.120859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(vid_name)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 134)\n",
    "ret, frame = cap.read()\n",
    "clear_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ],
   "id": "577938653d34b1b9",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:49:47.293287Z",
     "start_time": "2024-10-22T14:49:45.841348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(vid_name)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 1507)\n",
    "ret, frame = cap.read()\n",
    "object_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ],
   "id": "c367c3a1eb2d955e",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:32:22.988626Z",
     "start_time": "2024-10-22T14:32:22.982669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def draw_circle(event,x,y,flags,param):\n",
    "    #Because of the use of global variables, they must be defined before using them, outside of any functions\n",
    "    global radius, text_image, mask  \n",
    "    if flags == cv2.EVENT_FLAG_SHIFTKEY:\n",
    "            cv2.circle(mask,(x,y),radius,(0,0,0),-1)    \n",
    "    if flags == cv2.EVENT_FLAG_LBUTTON:\n",
    "        cv2.circle(mask,(x,y),radius,(255,255,255),-1)      \n",
    "        \n",
    "    text_image = cv2.rectangle(text_image, (0, 70), (35, 40), (255, 255, 255), -1)    \n",
    "    text_image = cv2.putText(text_image, str(radius), (0, 65), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.8, color=(0, 0, 255), thickness=2)         \n",
    "        "
   ],
   "id": "d376f909904ae9b1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:51:29.997730Z",
     "start_time": "2024-10-22T14:51:20.440879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Select frame with object in\n",
    "cap = cv2.VideoCapture(vid_name)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 1507)\n",
    "ret, frame = cap.read()\n",
    "object_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "# Run the mask creation code\n",
    "text_image = object_frame\n",
    "mask = np.zeros_like(object_frame, np.uint8)\n",
    "# Set the initial circle radius\n",
    "radius = 50\n",
    "line_1 = \"Click with the left mouse button to add, double click to remove\"\n",
    "line_2 = \"Up = radius + 5,\"\n",
    "line_3 = \"Down = radius - 5\"\n",
    "text_image = cv2.putText(text_image, line_1, (10, 10), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=2)  \n",
    "text_image = cv2.putText(text_image, line_2, (10, 22), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=2)  \n",
    "text_image = cv2.putText(text_image, line_3, (10, 34), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=2)  \n",
    "combined_image = cv2.bitwise_or(text_image, mask)\n",
    "cv2.namedWindow('Mask On Frame')\n",
    "cv2.imshow('Mask On Frame', combined_image)\n",
    "cv2.setMouseCallback('Mask On Frame',draw_circle)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    combined_image = cv2.bitwise_or(text_image, mask)\n",
    "    cv2.imshow('Mask On Frame',combined_image)\n",
    "    cv2.imshow('Mask',mask)\n",
    "    k = cv2.waitKey(20) & 0xFF\n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "    if k == 82:\n",
    "        #upkey\n",
    "        radius = radius + 5\n",
    "    if k == 84:\n",
    "        #downkey\n",
    "        radius = radius - 5\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "66a78e8a8fbb8af7",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:51:31.814989Z",
     "start_time": "2024-10-22T14:51:31.811913Z"
    }
   },
   "cell_type": "code",
   "source": "object_mask = mask",
   "id": "c34e7a89071f8248",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:51:06.364002Z",
     "start_time": "2024-10-22T14:51:01.846445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Find initial moment\n",
    "contours, hierarchy = cv2.findContours(object_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "image_frame = object_frame.copy()\n",
    "# Draw contours:\n",
    "cv2.drawContours(image_frame, contours, 0, (0, 255, 0), 2)\n",
    "\n",
    "# Calculate image moments of the detected contour\n",
    "M = cv2.moments(contours[0])\n",
    "\n",
    "# Print center (debugging):\n",
    "print(\"center X : '{}'\".format(round(M['m10'] / M['m00'])))\n",
    "print(\"center Y : '{}'\".format(round(M['m01'] / M['m00'])))\n",
    "\n",
    "# Draw a circle based centered at centroid coordinates\n",
    "cv2.circle(image_frame, (round(M['m10'] / M['m00']), round(M['m01'] / M['m00'])), 5, (0, 255, 0), -1)\n",
    "# Show image:\n",
    "cv2.imshow(\"outline contour & centroid\", text_image)\n",
    "\n",
    "# Wait until a key is pressed:\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Destroy all created windows:\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "a1b8e8263cb6a239",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center X : '732'\n",
      "center Y : '560'\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:51:39.442248Z",
     "start_time": "2024-10-22T14:51:33.893795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Attempt to refine the mask\n",
    "thresh = cv2.mean(object_frame, mask=cv2.bitwise_not(object_mask))[0]\n",
    "average_bg = cv2.bitwise_and(cv2.bitwise_not(object_mask), thresh)\n",
    "masked_seed = cv2.bitwise_and(object_frame, object_frame, mask=object_mask)\n",
    "thresh_bg = np.ones_like(object_frame)*np.ceil(thresh).astype(np.uint8)\n",
    "average_image = cv2.bitwise_xor(masked_seed, average_bg)\n",
    "\n",
    "# global thresholding\n",
    "ret1,th1 = cv2.threshold(object_frame,127,255,cv2.THRESH_BINARY)\n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv2.threshold(average_image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv2.GaussianBlur(average_image,(7,7),0)\n",
    "ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"blended\", average_image)\n",
    "cv2.imshow(\"th1\", th1)\n",
    "cv2.imshow(\"th2\", th2)\n",
    "cv2.imshow(\"th3\", th3)\n",
    "\n",
    "# Wait until a key is pressed:\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Destroy all created windows:\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "810ddd96addfce8c",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T15:54:03.983326Z",
     "start_time": "2024-10-22T15:54:01.373560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src = th3.copy()\n",
    "import random as rng\n",
    "\n",
    "# Create Window\n",
    "source_window = 'Source'\n",
    "cv2.namedWindow(source_window, cv2.WINDOW_NORMAL)\n",
    "\n",
    "cv2.imshow('Source', src)\n",
    "color = []\n",
    "for n in range(0,20):\n",
    "    color.append((rng.randint(0,256), rng.randint(0,256), rng.randint(0,256)))\n",
    "\n",
    "    blur_fg = cv2.blur(src, (3,3))\n",
    "    # Find contours\n",
    "    contours,_ = cv2.findContours(blur_fg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    edges = np.empty((0,2), dtype=np.uint8)\n",
    "    \n",
    "    #Find the overall contour\n",
    "    for i in range(len(contours)):\n",
    "        if len(contours[i]) > 15:\n",
    "            edges = np.concatenate([edges, *contours[i]])\n",
    "    \n",
    "    convex_hull = cv2.convexHull(edges)\n",
    "    drawing = np.zeros_like(src, dtype=np.uint8)\n",
    "    new_mask  = np.zeros_like(src, dtype=np.uint8)\n",
    "    new_edge = object_frame.copy()\n",
    "    cv2.drawContours(drawing, [convex_hull], -1, color[0], 3)\n",
    "    cv2.drawContours(new_edge, [convex_hull], -1, color[0], 3)\n",
    "    cv2.drawContours(new_mask, [convex_hull], -1, (255,255,255), -1)\n",
    "    \n",
    "    x,y = find_centre([convex_hull]) #This is called 39 times and I don't know how to stop it\n",
    "    cv2.circle(new_mask, ( x, y), 5, (0, 255, 0), -1)\n",
    "    \n",
    "    \n",
    "while True:\n",
    "    # Show in a window\n",
    "    cv2.imshow('Contours', drawing)\n",
    "    cv2.imshow('New', new_edge)\n",
    "    cv2.imshow('New Mask', new_mask)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "a390927cf91d60b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n",
      "719\n",
      "592\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:52:05.924092Z",
     "start_time": "2024-10-22T14:52:05.920368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Find the moment of the reduced mask\n",
    "def find_centre(contours):\n",
    "    \n",
    "    # Calculate image moments of the detected contour\n",
    "    M = cv2.moments(contours[0])\n",
    "    \n",
    "    # Print center (debugging):\n",
    "    x = round(M['m10'] / M['m00'])\n",
    "    y = round(M['m01'] / M['m00'])\n",
    "    \n",
    "    print(x)\n",
    "    print(y)\n",
    "        \n",
    "    return x,y"
   ],
   "id": "9e09870a5124d838",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:37:57.549660Z",
     "start_time": "2024-10-02T17:37:57.497926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Apply an affine warp to the mask\n",
    "affine = cv2.getAffineTransform([cv2.KeyPoint[0,0],[0,5],[5,0]], [[45,45],[45,50],[50,45]])\n",
    "\n",
    "out = cv2.warpAffine(new_edge, affine, (new_mask.shape[1], new_mask.shape[0]))\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('New Mask', new_mask)\n",
    "    cv2.imshow('Transformed Mask', out)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "d2bd16a7053c2e08",
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'getAffineTransform'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[208], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#Apply an affine warp to the mask\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m affine \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetAffineTransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m45\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m45\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m45\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m45\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m out \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mwarpAffine(new_edge, affine, (new_mask\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], new_mask\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]))\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'getAffineTransform'\n> Overload resolution failed:\n>  - src is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'src'\n"
     ]
    }
   ],
   "execution_count": 208
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-22T14:52:33.564766Z",
     "start_time": "2024-10-22T14:52:27.944486Z"
    }
   },
   "source": [
    "# generate initial corners of detected object\n",
    "# set limit, minimum distance in pixels and quality of object corner to be tracked\n",
    "parameters_shitomasi = dict(maxCorners=100, qualityLevel=0.3, minDistance=7)\n",
    "# set min size of tracked object, e.g. 15x15px\n",
    "parameter_lucas_kanade = dict(winSize=(40, 40), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(vid_name)\n",
    "# Read the first frame\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 2934)\n",
    "ret, frame = cap.read()\n",
    "frame_gray_init = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "# Use Shi-Tomasi to detect object corners / edges from initial frame\n",
    "edges = cv2.goodFeaturesToTrack(frame_gray_init, mask = object_mask, **parameters_shitomasi)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('Frame', frame_gray)\n",
    "\n",
    "\n",
    "    # create a black canvas the size of the initial frame\n",
    "    canvas = np.zeros_like(frame)\n",
    "    # create random colours for visualization for all 100 max corners for RGB channels\n",
    "    colours = np.random.randint(0, 255, (100, 3))\n",
    "    \n",
    "    # update object corners by comparing with found edges in initial frame\n",
    "    update_edges, status, errors = cv2.calcOpticalFlowPyrLK(frame_gray_init, frame_gray, edges, None,\n",
    "                                                         **parameter_lucas_kanade)\n",
    "    # only update edges if algorithm successfully tracked\n",
    "    new_edges = update_edges[status == 1]\n",
    "    # to calculate directional flow we need to compare with previous position\n",
    "    old_edges = edges[status == 1]\n",
    "\n",
    "    for i, (new, old) in enumerate(zip(new_edges, old_edges)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "\n",
    "        # draw line between old and new corner point with random colour\n",
    "        mask = cv2.line(canvas, (int(a), int(b)), (int(c), int(d)), colours[i].tolist(), 2)\n",
    "        # draw circle around new position\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, colours[i].tolist(), -1)\n",
    "\n",
    "    result = cv2.add(frame, mask)\n",
    "    cv2.imshow('Optical Flow (sparse)', result)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    # overwrite initial frame with current before restarting the loop\n",
    "    frame_gray_init = frame_gray.copy()\n",
    "    # update to new edges before restarting the loop\n",
    "    edges = new_edges.reshape(-1, 1, 2)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:22:57.831720Z",
     "start_time": "2024-10-02T12:22:57.814753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "987f0be84b207f6d",
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
