{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:48:13.027949Z",
     "start_time": "2024-10-02T11:48:13.022652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ],
   "id": "77a3811bf950cf4b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:48:14.566089Z",
     "start_time": "2024-10-02T11:48:14.557893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "video_folder = \"/home/persie/Videos/mokap/\"\n",
    "session_id = os.listdir(video_folder)\n",
    "video_file = []\n",
    "for folder in session_id:\n",
    "    files = os.listdir(os.path.join(video_folder, folder))\n",
    "    for file in files:\n",
    "        video_file.append(os.path.join(video_folder, folder, file))\n"
   ],
   "id": "2fa20492f9bae5fb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:48:16.389857Z",
     "start_time": "2024-10-02T11:48:16.246411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(video_file[33])\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 134)\n",
    "ret, frame = cap.read()\n",
    "clear_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ],
   "id": "577938653d34b1b9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:40:09.558603Z",
     "start_time": "2024-10-02T15:40:08.172493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(video_file[33])\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 1507)\n",
    "ret, frame = cap.read()\n",
    "object_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ],
   "id": "c367c3a1eb2d955e",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T11:49:34.451861Z",
     "start_time": "2024-10-02T11:49:34.439826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def draw_circle(event,x,y,flags,param):\n",
    "    #Because of the use of global variables, they must be defined before using them, outside of any functions\n",
    "    global radius, text_image, mask  \n",
    "    if flags == cv2.EVENT_FLAG_SHIFTKEY:\n",
    "            cv2.circle(mask,(x,y),radius,(0,0,0),-1)    \n",
    "    if flags == cv2.EVENT_FLAG_LBUTTON:\n",
    "        cv2.circle(mask,(x,y),radius,(255,255,255),-1)      \n",
    "        \n",
    "    text_image = cv2.rectangle(text_image, (0, 70), (35, 40), (255, 255, 255), -1)    \n",
    "    text_image = cv2.putText(text_image, str(radius), (0, 65), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.8, color=(0, 0, 255), thickness=2)         \n",
    "        "
   ],
   "id": "d376f909904ae9b1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:20:58.106986Z",
     "start_time": "2024-10-02T12:20:38.802461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Select frame with object in\n",
    "cap = cv2.VideoCapture(video_file[33])\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 1507)\n",
    "ret, frame = cap.read()\n",
    "object_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "# Run the mask creation code\n",
    "text_image = object_frame\n",
    "mask = np.zeros_like(object_frame, np.uint8)\n",
    "# Set the initial circle radius\n",
    "radius = 50\n",
    "line_1 = \"Click with the left mouse button to add, double click to remove\"\n",
    "line_2 = \"Up = radius + 5,\"\n",
    "line_3 = \"Down = radius - 5\"\n",
    "text_image = cv2.putText(text_image, line_1, (10, 10), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=2)  \n",
    "text_image = cv2.putText(text_image, line_2, (10, 22), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=2)  \n",
    "text_image = cv2.putText(text_image, line_3, (10, 34), cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.5, color=(0, 255, 0), thickness=2)  \n",
    "combined_image = cv2.bitwise_or(text_image, mask)\n",
    "cv2.namedWindow('Mask On Frame')\n",
    "cv2.imshow('Mask On Frame', combined_image)\n",
    "cv2.setMouseCallback('Mask On Frame',draw_circle)\n",
    "\n",
    "\n",
    "while(1):\n",
    "    combined_image = cv2.bitwise_or(text_image, mask)\n",
    "    cv2.imshow('Mask On Frame',combined_image)\n",
    "    cv2.imshow('Mask',mask)\n",
    "    k = cv2.waitKey(20) & 0xFF\n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "    if k == 82:\n",
    "        #upkey\n",
    "        radius = radius + 5\n",
    "    if k == 84:\n",
    "        #downkey\n",
    "        radius = radius - 5\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "66a78e8a8fbb8af7",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:21:03.141123Z",
     "start_time": "2024-10-02T12:21:03.130844Z"
    }
   },
   "cell_type": "code",
   "source": "object_mask = mask",
   "id": "c34e7a89071f8248",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T15:14:04.663489Z",
     "start_time": "2024-10-02T15:13:59.757657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Find initial moment\n",
    "contours, hierarchy = cv2.findContours(object_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Draw contours:\n",
    "cv2.drawContours(object_frame, contours, 0, (0, 255, 0), 2)\n",
    "\n",
    "# Calculate image moments of the detected contour\n",
    "M = cv2.moments(contours[0])\n",
    "\n",
    "# Print center (debugging):\n",
    "print(\"center X : '{}'\".format(round(M['m10'] / M['m00'])))\n",
    "print(\"center Y : '{}'\".format(round(M['m01'] / M['m00'])))\n",
    "\n",
    "# Draw a circle based centered at centroid coordinates\n",
    "cv2.circle(object_frame, (round(M['m10'] / M['m00']), round(M['m01'] / M['m00'])), 5, (0, 255, 0), -1)\n",
    "\n",
    "# Show image:\n",
    "cv2.imshow(\"outline contour & centroid\", text_image)\n",
    "\n",
    "# Wait until a key is pressed:\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Destroy all created windows:\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "a1b8e8263cb6a239",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center X : '751'\n",
      "center Y : '542'\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T16:06:51.474019Z",
     "start_time": "2024-10-02T16:06:41.693411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Attempt to refine the mask\n",
    "thresh = cv2.mean(object_frame, mask=cv2.bitwise_not(object_mask))[0]\n",
    "average_bg = cv2.bitwise_and(cv2.bitwise_not(object_mask), thresh)\n",
    "masked_seed = cv2.bitwise_and(object_frame, object_frame, mask=object_mask)\n",
    "thresh_bg = np.ones_like(object_frame)*np.ceil(thresh).astype(np.uint8)\n",
    "average_image = cv2.bitwise_xor(masked_seed, average_bg)\n",
    "\n",
    "# global thresholding\n",
    "ret1,th1 = cv2.threshold(object_frame,127,255,cv2.THRESH_BINARY)\n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv2.threshold(average_image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv2.GaussianBlur(average_image,(7,7),0)\n",
    "ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"blended\", average_image)\n",
    "cv2.imshow(\"th1\", th1)\n",
    "cv2.imshow(\"th2\", th2)\n",
    "cv2.imshow(\"th3\", th3)\n",
    "\n",
    "# Wait until a key is pressed:\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Destroy all created windows:\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "810ddd96addfce8c",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T17:06:43.912488Z",
     "start_time": "2024-10-02T17:05:38.476786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src = th3.copy()\n",
    "import random as rng\n",
    "def thresh_callback(val):\n",
    "    global thresh\n",
    "    thresh = val\n",
    "    \n",
    "\n",
    "# Create Window\n",
    "source_window = 'Source'\n",
    "cv2.namedWindow(source_window, cv2.WINDOW_NORMAL)\n",
    "max_thresh = 255\n",
    "\n",
    "thresh = 25 # initial threshold\n",
    "cv2.createTrackbar('Canny thresh:', source_window, thresh, max_thresh, thresh_callback)\n",
    "thresh_callback(thresh)\n",
    "cv2.imshow('Source', src)\n",
    "color = []\n",
    "for n in range(0,20):\n",
    "    color.append((rng.randint(0,256), rng.randint(0,256), rng.randint(0,256)))\n",
    "\n",
    "\n",
    "    blur_fg = cv2.blur(src, (3,3))\n",
    "    # Detect edges using Canny\n",
    "    canny_output = cv2.Canny(blur_fg, thresh, thresh * 2)\n",
    "    # Find contours\n",
    "    contours,_ = cv2.findContours(canny_output, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    edges = np.empty((0,2), dtype=np.uint8)\n",
    "    \n",
    "    #Find the overall contour\n",
    "    for i in range(len(contours)):\n",
    "        if len(contours[i]) > 1:\n",
    "            edges = np.concatenate([edges, *contours[i]])\n",
    "    \n",
    "    convex_hull = cv2.convexHull(edges)\n",
    "    drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
    "    new_edge = object_frame.copy()\n",
    "    cv2.drawContours(drawing, [convex_hull], -1, color[0], 1)\n",
    "    cv2.drawContours(new_edge, [convex_hull], -1, color[0], 1)\n",
    "    \n",
    "    \n",
    "while True:\n",
    "    # Show in a window\n",
    "    cv2.imshow('Contours', drawing)\n",
    "    cv2.imshow('New', new_edge)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "a390927cf91d60b",
   "outputs": [],
   "execution_count": 176
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-02T15:11:19.450938Z",
     "start_time": "2024-10-02T15:11:13.287070Z"
    }
   },
   "source": [
    "# generate initial corners of detected object\n",
    "# set limit, minimum distance in pixels and quality of object corner to be tracked\n",
    "parameters_shitomasi = dict(maxCorners=100, qualityLevel=0.3, minDistance=7)\n",
    "# set min size of tracked object, e.g. 15x15px\n",
    "parameter_lucas_kanade = dict(winSize=(40, 40), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(video_file[33])\n",
    "# Read the first frame\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 2934)\n",
    "ret, frame = cap.read()\n",
    "frame_gray_init = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "# Use Shi-Tomasi to detect object corners / edges from initial frame\n",
    "edges = cv2.goodFeaturesToTrack(frame_gray_init, mask = object_mask, **parameters_shitomasi)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('Frame', frame_gray)\n",
    "\n",
    "\n",
    "    # create a black canvas the size of the initial frame\n",
    "    canvas = np.zeros_like(frame)\n",
    "    # create random colours for visualization for all 100 max corners for RGB channels\n",
    "    colours = np.random.randint(0, 255, (100, 3))\n",
    "    \n",
    "    # update object corners by comparing with found edges in initial frame\n",
    "    update_edges, status, errors = cv2.calcOpticalFlowPyrLK(frame_gray_init, frame_gray, edges, None,\n",
    "                                                         **parameter_lucas_kanade)\n",
    "    # only update edges if algorithm successfully tracked\n",
    "    new_edges = update_edges[status == 1]\n",
    "    # to calculate directional flow we need to compare with previous position\n",
    "    old_edges = edges[status == 1]\n",
    "\n",
    "    for i, (new, old) in enumerate(zip(new_edges, old_edges)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "\n",
    "        # draw line between old and new corner point with random colour\n",
    "        mask = cv2.line(canvas, (int(a), int(b)), (int(c), int(d)), colours[i].tolist(), 2)\n",
    "        # draw circle around new position\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, colours[i].tolist(), -1)\n",
    "\n",
    "    result = cv2.add(frame, mask)\n",
    "    cv2.imshow('Optical Flow (sparse)', result)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    # overwrite initial frame with current before restarting the loop\n",
    "    frame_gray_init = frame_gray.copy()\n",
    "    # update to new edges before restarting the loop\n",
    "    edges = new_edges.reshape(-1, 1, 2)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T12:22:57.831720Z",
     "start_time": "2024-10-02T12:22:57.814753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "987f0be84b207f6d",
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
